---
title: "Lab"
subtitle: "AI Research Agent"
description: "Chat with an AI that cites its sources. Get answers grounded in your indexed documentation with transparent thinking steps and inline citations."
icon: "brain"
color: "purple"
order: 2
highlights:
  - "Citation-backed responses from your sources"
  - "Transparent thinking steps you can follow"
  - "Smart prompt suggestions for deeper research"
  - "Multi-turn conversations with context"
  - "Inline citations you can verify"
  - "Artifact generation for reports and memos"
useCases:
  - persona: "AI Engineer"
    title: "Deep-Dive Technical Comparisons"
    description: "Ask complex questions about model capabilities, API differences, and implementation details. Get answers with citations to verify."
  - persona: "Product Manager"
    title: "Quick Answers for Stakeholders"
    description: "Get instant, sourced answers to executive questions about AI capabilities, pricing, and timelines."
  - persona: "Enterprise Architect"
    title: "Architecture Decision Support"
    description: "Explore trade-offs between deployment options, security models, and integration patterns with documented evidence."
screenshot: "/assets/screenshots/lab-chat.png"
---

## Your AI Research Assistant

Lab is where you interact with your indexed knowledge base through natural conversation. Ask questions, explore topics, and get answers that are always grounded in your sources.

### Citation-First Responses

Every response from Lab includes inline citations linking back to specific sources. No more wondering "where did this information come from?" — every claim is traceable.

```
User: What's the context window for Claude 3 Opus?

Lab: Claude 3 Opus supports a 200K token context window [1],
making it suitable for processing long documents and maintaining
extended conversations [2].

[1] Anthropic Model Card - Claude 3 Opus
[2] Anthropic API Documentation - Context Windows
```

### Transparent Thinking

Watch the AI's reasoning process unfold in real-time:

1. **Understanding** — See how Lab interprets your question
2. **Searching** — Watch as it searches your indexed sources
3. **Synthesizing** — Follow along as it builds its response
4. **Citing** — Observe citations being added as claims are made

### Smart Prompts

Not sure what to ask? Lab suggests relevant follow-up questions based on your conversation context and available sources:

- "What are the pricing differences between Claude and GPT-4?"
- "How do the safety approaches compare across vendors?"
- "What enterprise features does each vendor offer?"

### Multi-Turn Conversations

Lab maintains context across your entire conversation. Build on previous questions, drill deeper into topics, and explore tangents — all while keeping your research organized.

### Generate Artifacts

When you've gathered insights worth sharing, turn your conversation into exportable artifacts:

- **Comparison Tables** — Side-by-side feature matrices
- **Decision Memos** — Executive summaries with recommendations
- **Research Reports** — Comprehensive analysis with full citations

> "Lab doesn't just answer questions — it shows its work. I can trust the responses because I can verify every claim." — Senior AI Researcher
