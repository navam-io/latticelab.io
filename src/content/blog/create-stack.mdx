---
title: "Creating a Stack Configuration"
description: "Configure model, framework, and hardware options for your AI infrastructure stack."
pubDate: 2025-11-28
author: "Lattice Lab"
tags: ["stacks", "configuration", "infrastructure"]
featuredImage: "/images/journeys/create-stack/create-stack-01.png"
journey: "create-stack"
---

**When I** need to define my infrastructure, **I want to** create a stack, **so I can** specify model, framework, and hardware options.

---

## Introduction

A stack defines your complete AI infrastructure configuration. From the model provider to the cloud region, stacks capture the technical decisions that power your application.

## Stack Components

### Model Configuration

- **Provider** — Anthropic, OpenAI, Google, NVIDIA, etc.
- **Model ID** — Specific model version
- **Temperature** — Response variability
- **Max Tokens** — Output length limit
- **Context Length** — Input window size

### Framework Selection

- **Orchestration** — LangGraph, LangChain, custom
- **Observability** — Logging and monitoring
- **Caching** — Response caching strategy

### Hardware Options

- **Cloud Provider** — AWS, GCP, Azure
- **Region** — Deployment location
- **Instance Type** — CPU/GPU configuration
- **Scaling** — Auto-scaling settings

## Using Templates

Start from pre-built templates:
- **Speed Stack** — Optimized for low latency
- **Cost Stack** — Optimized for budget
- **Quality Stack** — Maximum capability

## Linking to Scenarios

Stacks can be linked to scenarios to enable:
- Automatic validation against requirements
- Cost projections based on workload
- Compatibility checking

**Next steps:** Link your stack to a scenario for validation.
